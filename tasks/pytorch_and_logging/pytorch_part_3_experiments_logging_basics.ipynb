{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1516e1b",
   "metadata": {},
   "source": [
    "# Логирование экспериментов\n",
    "\n",
    "Составители туториала: [Артем Мухин](https://github.com/Banayaki)\n",
    "\n",
    "Для исследователей крайне важно содержать в чистоте результаты экспериментов, так как при поиске архитектур, гиперпараметров и т.д. может быть воспроизведено большое количество экспериментов. Если число проведенных экспериментов превышает десятки, становится крайне сложно следить за результатами и производить перекрестное сравнение, находить ошибки, выбирать лучший вариант. \n",
    "\n",
    "Для борьбы с вышеперечисленными проблемами созданы инструменты логирования и агрегирования экспериментов такие как:\n",
    " * [`weights and biases`](https://wandb.ai/site)\n",
    " * [`mlflow`](https://mlflow.org/)\n",
    " * [`comet.ml`](https://www.comet.ml/)\n",
    " * [`Tensorboard`](https://www.tensorflow.org/tensorboard)\n",
    " \n",
    "Большинство из данынх инструментов распространяются на платной основе. Однако чаще всего студенты могут получит полный доступ к инструменту, зарегестрировавшись, используя почту с доменом университета или github аккаунт, подтвержденный в github-students.\n",
    "\n",
    "В настоящем руководстве будет рассмотрен только инструмент `comet.ml`. С условиями бесплатного использования можно ознакомиться на [официальном сайте](https://www.comet.ml/site/pricing/) . \n",
    "\n",
    "Для использования `comet.ml` необходимо установить пакет `comet-ml`\n",
    "\n",
    "`pip install comet-ml==3.26.1`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b914aa8",
   "metadata": {},
   "source": [
    "## Comet.ml в `Pytorch`\n",
    "Возьмем в качестве исходного кода - код используемый в файле `pytorch_basics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "283dc798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "954487dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = 'cuda:1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e93eca",
   "metadata": {},
   "source": [
    "Создадим объект эксперимента.\n",
    "\n",
    "Для его создания нужно иметь `API_KEY`, который **можно получить в ЛК comet.ml**\n",
    "\n",
    "Данный объект имеет большой набор параметров, о которых вы можете узнать из документации, однако нас устроят и стандартные значения параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562e374d",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(\n",
    "    api_key='***',\n",
    "    project_name='pytorch_cometml_lightning',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cd985a",
   "metadata": {},
   "source": [
    "### Название эксперимента и теги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2ec57e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.set_name(\"Testing comet.ml logging\")\n",
    "experiment.add_tag(\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec66dff0",
   "metadata": {},
   "source": [
    "После создания объекта эксперимента, он появится в comet.ml в соответствующем проекте. \n",
    "\n",
    "![Overview](./imgs/overivew.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7eb349",
   "metadata": {},
   "source": [
    "### Логирование гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca221cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 1024,\n",
    "    \"num_workers\": 4,\n",
    "    \"in_channels\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "278b765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.log_parameters(hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4143c908",
   "metadata": {},
   "source": [
    "Выполнив метод выше, мы можем увидеть, что переданные гиперпараметры сохранились в `comet.ml`\n",
    "\n",
    "![Hyperparameters](./imgs/hyperparameters_logging.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f2f175",
   "metadata": {},
   "source": [
    "### Логирование метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46e563eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, dataloader, experiment: Experiment):\n",
    "    step = 0\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        # Откроем контекст в котором производится шаг обучения сети\n",
    "        # Это опционально\n",
    "        with experiment.train():\n",
    "            loss_train = 0.0\n",
    "            model.train()\n",
    "            for X, y in tqdm(dataloader):\n",
    "                X = X.to(device=device)\n",
    "                y = y.to(device=device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                pred = model(X)\n",
    "                loss = loss_fn(pred, y)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Добавим логгирование значений лосса\n",
    "                experiment.log_metric(\"TrainLoss\", loss.item(), step=step, epoch=epoch)\n",
    "                step += 1\n",
    "                loss_train += loss.item()\n",
    "        \n",
    "        # Тестирование модели\n",
    "        if epoch == 1 or epoch % 2 == 0:\n",
    "            with experiment.test():\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    size = len(dataloader.dataset)\n",
    "                    correct = 0\n",
    "                    for X, y in dataloader:\n",
    "                        X = X.to(device=device)\n",
    "                        y = y.to(device=device)\n",
    "                        pred = model(X)\n",
    "                        correct += (pred.argmax(dim=1) == y).type(torch.float).sum().item()\n",
    "                    acc = correct / size\n",
    "                \n",
    "                # Логирование значений точности\n",
    "                experiment.log_metric('Accuracy', acc, epoch=epoch)\n",
    "                print('{} Epoch {}, Training loss {}, Accuracy {}'.format(\n",
    "                    datetime.datetime.now(), epoch,\n",
    "                    loss_train / len(dataloader), acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83112000",
   "metadata": {},
   "source": [
    "### Подготовим все необходимое для обучения нейронной сети и запустим процесс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af912ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = transforms.Compose([\n",
    "    transforms.RandomRotation((-30, 30)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed93d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', \n",
    "    download=False, \n",
    "    train=True,\n",
    "    transform=augmentation\n",
    ")\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=hyperparameters['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=hyperparameters['num_workers']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6eeef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet18(nn.Module):\n",
    "    def __init__(self, n_channels: int = 1, n_classes: int = 10):\n",
    "        super().__init__()\n",
    "        self.resnet = torchvision.models.resnet18(pretrained=False)\n",
    "        # Заменим первую свертку\n",
    "        self.resnet.conv1 = nn.Conv2d(in_channels=n_channels, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.resnet.fc = nn.Linear(in_features=self.resnet.fc.in_features, out_features=n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        hx = self.resnet(x)\n",
    "        return hx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a150e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet18(n_channels=hyperparameters['in_channels']).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60f7a2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=hyperparameters['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "967282a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fdd3a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:06<00:00,  9.34it/s]\n",
      "  0%|          | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-19 07:27:57.519771 Epoch 1, Training loss 0.5988685771570368, Accuracy 0.8247833333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:04<00:00, 11.99it/s]\n",
      "  0%|          | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-19 07:28:05.131737 Epoch 2, Training loss 0.40655929607860114, Accuracy 0.8408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:04<00:00, 11.98it/s]\n",
      "100%|██████████| 59/59 [00:04<00:00, 11.98it/s]\n",
      "  0%|          | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-19 07:28:17.645883 Epoch 4, Training loss 0.33912664500333495, Accuracy 0.8788333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:04<00:00, 11.95it/s]\n",
      "100%|██████████| 59/59 [00:05<00:00, 11.77it/s]\n",
      "  0%|          | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-19 07:28:30.373786 Epoch 6, Training loss 0.30487178846941154, Accuracy 0.86105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:04<00:00, 11.82it/s]\n",
      "100%|██████████| 59/59 [00:05<00:00, 11.80it/s]\n",
      "  0%|          | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-19 07:28:43.244678 Epoch 8, Training loss 0.28035432832725976, Accuracy 0.8845333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:05<00:00, 11.78it/s]\n",
      "100%|██████████| 59/59 [00:04<00:00, 11.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-19 07:28:55.880353 Epoch 10, Training loss 0.2616798769114381, Accuracy 0.8946333333333333\n"
     ]
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 10,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    dataloader = dataloader,\n",
    "    experiment = experiment\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1015601",
   "metadata": {},
   "source": [
    "**Важно после окончания эксперимента выполнить следующий вызов метода!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa05451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d41a239",
   "metadata": {},
   "source": [
    "В процессе обучения графики в comet.ml обновляются динамически, что позволяет нам в реальном времени следить за экспериментом (множество экспериментов на общем графике).\n",
    "Рассмотрим некоторые возможности, которые предоставил нам comet.ml **(заметьте, мы добавили только логирование гиперпараметров, значений ошибки во время обучения и значений метрики точности)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284a1afb",
   "metadata": {},
   "source": [
    "1 Вкладка `Charts`\n",
    "\n",
    "Здесь мы можем сейчас наблюдать несколько графиков (comet.ml автоматически генерирует графики из имеющихся у него данных, однако мы вольны сами настроить их отображение в случае необходимости. Настроить их подписи, вид (например bar-chart вместо графиков) и т.д.).\n",
    "\n",
    "Обратимся к рисунку.\n",
    "\n",
    "![Charts](./imgs/charts.png)\n",
    "\n",
    "На рисунке видно три графика, два из них идентичные (за исключением параметра сглаживания). Они отображают значения функции ошибки по мере обучения нейронной сети. И еще один график - на нем видны значения точности нейронной сети.\n",
    "\n",
    "2 Вкладка `Panels` \n",
    "\n",
    "Предназначена для настройки чего-то вроде `Dashboard`, где вы можете настроить детально, какую информацию выводить на экран. На рисунке ниже можно увидеть доступные view которые можно добавить в panels.\n",
    "\n",
    "![Panels](./imgs/panels.png)\n",
    "\n",
    "3 Вкладка `Code`\n",
    "\n",
    "После завершения эксперимента весь исполняемый код сохраняется в comet.ml. Это может быть крайне полезно для воспроизведения эксперимента. \n",
    "\n",
    "4 Вкладка `Metrics` \n",
    "\n",
    "Позволяет наблюдать за метриками в табличном представлении\n",
    "\n",
    "![Metrics](./imgs/metrics.png)\n",
    "\n",
    "6 Вкладка `GraphDefinition`\n",
    "\n",
    "Позволяет взглянуть на структуру нейронной сети, в нашем случае полезной информации там не оказалось, несмотря на то, что автоматическое логирование включено. В таких случаях можно логировать структуру сети вручную, используя метод `set_model_graph()`.\n",
    "\n",
    "7 Вкладка `Output`\n",
    "\n",
    "Показывает вывод в потоки stdout, stderr, которые были произведены во время выполнения эксперимента. Может пригодиться для логирования ошибок.\n",
    "\n",
    "8 Вкладка `System Metrics`\n",
    "\n",
    "Позволяет наблюдать за потреблением ресурсов системы, на которой происходит эксперимент. Здесь можно также заметить, хорошо ли нейронная сеть утилизирует возможности GPU. \n",
    "\n",
    "9 Вкладка `Graphics`\n",
    "\n",
    "Данная вкладка может быть крайне полезна при работе с изображениями. Сюда можно добавлять вручную созданные (например через matplotlib) сложные графики или просто изображения (например результаты сегментации изображения). На следующем изображении указан пример, как использовалась данная возможность в одном из проектов по сегментации изображений.\n",
    "\n",
    "![Graphics](./imgs/graphics.png)\n",
    "\n",
    "10 Вкладка `Confusion Matrices`\n",
    "\n",
    "В настоящем примере мы не логировали данные матрицы, однако на рисунке ниже приведен пример того, как они отображаются. Для их логирования в объекте эксперимента также есть специальный метод.\n",
    "\n",
    "![ConfMatrix](./imgs/conf_matrix.png)\n",
    "\n",
    "11 Вкладка `Histograms`\n",
    "\n",
    "В данной вкладке можно логировать гистограммы распределений весов нейронной сети, что может быть полезно при их исследовании и поиске проблем. По ним можно явно определить что происходит с весами на каждом слое.\n",
    "\n",
    "12 Вкладки `HTML` и `Notes`\n",
    "\n",
    "В данных вкладках удобно оставлять описания экспериментов. Вкладка `Notes` доступна для редактирования только с самого сайта. `HTML` же можно генерировать внутри кода эксперимента."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a18b71e",
   "metadata": {},
   "source": [
    "## Сравнение экспериментов между собой"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f817652",
   "metadata": {},
   "source": [
    "Находясь в режиме `Panels` (находясь в режиме просмотра экспериментов проекта), можно видеть результаты всех (или выбранных по определенному фильтру или вручную) экспериментов. Там же можно вручную настроить графики, если сгенерированные автоматически не позволяют провести качественную оценку результатов.\n",
    "\n",
    "Далее на рисунке изображено то, как может выглядть суммарный график, иллюстрирующий значение метрик IoU и DiceLoss для ряда экспериментов.\n",
    "\n",
    "![OverallBars](./imgs/overall_bars.png)\n",
    "\n",
    "На следующем рисунке отображен график динамики обучения нейронной сети в каждом эксперименте.\n",
    "\n",
    "![OverallLines](./imgs/overall_lines.png)\n",
    "\n",
    "По таким графикам удобно выбирать наилучшую модель / параметры и делать какие-либо выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe119d20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
